{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T12:55:15.549106Z",
     "iopub.status.busy": "2022-12-20T12:55:15.548759Z",
     "iopub.status.idle": "2022-12-20T12:55:15.556349Z",
     "shell.execute_reply": "2022-12-20T12:55:15.555356Z",
     "shell.execute_reply.started": "2022-12-20T12:55:15.549077Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras as keras\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T02:51:19.718228Z",
     "iopub.status.busy": "2022-12-13T02:51:19.717711Z",
     "iopub.status.idle": "2022-12-13T02:51:19.891226Z",
     "shell.execute_reply": "2022-12-13T02:51:19.887186Z",
     "shell.execute_reply.started": "2022-12-13T02:51:19.718176Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 75)        750       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 28, 28, 75)        300       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 14, 14, 75)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 14, 14, 50)        33800     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 14, 14, 50)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 14, 14, 50)        200       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 7, 7, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 7, 7, 25)          11275     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 7, 7, 25)          100       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 4, 4, 25)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               205312    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 38)                19494     \n",
      "=================================================================\n",
      "Total params: 271,231\n",
      "Trainable params: 270,931\n",
      "Non-trainable params: 300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    Conv2D,\n",
    "    MaxPool2D,\n",
    "    Flatten,\n",
    "    Dropout,\n",
    "    BatchNormalization,\n",
    ")\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(75, (3, 3), strides=1, padding=\"same\", activation=\"relu\", \n",
    "                 input_shape=(28, 28, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2, 2), strides=2, padding=\"same\"))\n",
    "model.add(Conv2D(50, (3, 3), strides=1, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2, 2), strides=2, padding=\"same\"))\n",
    "model.add(Conv2D(25, (3, 3), strides=1, padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2, 2), strides=2, padding=\"same\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=512, activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=38, activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-16T03:03:48.018535Z",
     "iopub.status.busy": "2022-10-16T03:03:48.017860Z",
     "iopub.status.idle": "2022-10-16T03:03:48.024573Z",
     "shell.execute_reply": "2022-10-16T03:03:48.023544Z",
     "shell.execute_reply.started": "2022-10-16T03:03:48.018498Z"
    }
   },
   "outputs": [],
   "source": [
    "# original:\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    zoom_range=0.1,  # Randomly zoom image\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,  # randomly flip images horizontally\n",
    "    vertical_flip=False, # Don't randomly flip images vertically\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-16T02:38:24.539736Z",
     "iopub.status.busy": "2022-10-16T02:38:24.539370Z",
     "iopub.status.idle": "2022-10-16T02:38:24.545766Z",
     "shell.execute_reply": "2022-10-16T02:38:24.544361Z",
     "shell.execute_reply.started": "2022-10-16T02:38:24.539705Z"
    }
   },
   "outputs": [],
   "source": [
    "# new:\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "                    rescale=1./255,\n",
    "                    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=45,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    "    vertical_flip=False\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 5\n",
    "\n",
    "TRAIN_DIR = '/kaggle/input/new-plant-diseases-dataset/train'\n",
    "TEST_DIR = '/kaggle/input/new-plant-diseases-dataset/test'\n",
    "\n",
    "train_generator = ImageDataGenerator().flow_from_directory(TRAIN_DIR, batch_size=BATCH_SIZE, target_size = (28, 28))\n",
    "test_generator = ImageDataGenerator().flow_from_directory(TEST_DIR, batch_size=BATCH_SIZE, target_size = (28, 28))\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "with tf.device(\"/device:GPU:0\"):\n",
    "    model.fit(\n",
    "            train_generator,\n",
    "            steps_per_epoch=10901//BATCH_SIZE,\n",
    "            epochs=EPOCHS,\n",
    "            validation_data=test_generator,\n",
    "            validation_steps=2698//BATCH_SIZE\n",
    "            )\n",
    "\n",
    "# Separate out our target values\n",
    "y_train = train_df['label']\n",
    "y_valid = valid_df['label']\n",
    "del train_df['label']\n",
    "del valid_df['label']\n",
    "\n",
    "# Separate our our image vectors\n",
    "x_train = train_df.values\n",
    "x_valid = valid_df.values\n",
    "\n",
    "# Turn our scalar targets into binary categories\n",
    "num_classes = 24\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_valid = keras.utils.to_categorical(y_valid, num_classes)\n",
    "\n",
    "# Normalize our image data\n",
    "x_train = x_train / 255\n",
    "x_valid = x_valid / 255\n",
    "\n",
    "# Reshape the image data for the convolutional network\n",
    "x_train = x_train.reshape(-1,28,28,1)\n",
    "x_valid = x_valid.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-16T03:03:56.436042Z",
     "iopub.status.busy": "2022-10-16T03:03:56.435643Z",
     "iopub.status.idle": "2022-10-16T03:03:56.508812Z",
     "shell.execute_reply": "2022-10-16T03:03:56.507758Z",
     "shell.execute_reply.started": "2022-10-16T03:03:56.436004Z"
    }
   },
   "outputs": [],
   "source": [
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-16T03:03:58.498283Z",
     "iopub.status.busy": "2022-10-16T03:03:58.496391Z",
     "iopub.status.idle": "2022-10-16T03:03:58.508809Z",
     "shell.execute_reply": "2022-10-16T03:03:58.507867Z",
     "shell.execute_reply.started": "2022-10-16T03:03:58.498235Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T12:54:00.083257Z",
     "iopub.status.busy": "2022-12-20T12:54:00.082877Z",
     "iopub.status.idle": "2022-12-20T12:54:00.091242Z",
     "shell.execute_reply": "2022-12-20T12:54:00.090001Z",
     "shell.execute_reply.started": "2022-12-20T12:54:00.083224Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n",
      "857/857 [==============================] - 11s 12ms/step - loss: 0.7633 - accuracy: 0.5911 - val_loss: 0.7521 - val_accuracy: 0.5897\n",
      "Epoch 2/10\n",
      "857/857 [==============================] - 10s 12ms/step - loss: 0.7785 - accuracy: 0.6122 - val_loss: 0.7323 - val_accuracy: 0.5422\n",
      "Epoch 3/10\n",
      "857/857 [==============================] - 10s 12ms/step - loss: 0.7794 - accuracy: 0.6154 - val_loss: 0.6044 - val_accuracy: 0.6551\n",
      "Epoch 4/10\n",
      "857/857 [==============================] - 10s 12ms/step - loss: 0.7087 - accuracy: 0.7013 - val_loss: 0.5521 - val_accuracy: 0.7001\n",
      "Epoch 5/10\n",
      "857/857 [==============================] - 10s 12ms/step - loss: 0.6479 - accuracy: 0.7771 - val_loss: 0.5828 - val_accuracy: 0.7323\n",
      "Epoch 6/10\n",
      "857/857 [==============================] - 11s 12ms/step - loss: 0.6535 - accuracy: 0.7896 - val_loss: 0.6077 - val_accuracy: 0.7199\n",
      "Epoch 7/10\n",
      "857/857 [==============================] - 10s 11ms/step - loss: 0.5644 - accuracy: 0.8023 - val_loss: 0.5233 - val_accuracy: 0.8011\n",
      "Epoch 8/10\n",
      "857/857 [==============================] - 10s 12ms/step - loss: 0.4021 - accuracy: 0.8232 - val_loss: 0.4954 - val_accuracy: 0.8145\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 203s 11ms/step - loss: 0.4475 - accuracy: 0.8523 - val_loss: 0.4923 - val_accuracy: 0.8288\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 187s 15ms/step - loss: 0.4145 - accuracy: 0.8633 - val_loss: 0.3998 - val_accuracy: 0.9025\n"
     ]
    }
   ],
   "source": [
    "model.fit(img_iter,\n",
    "          epochs=10,\n",
    "          steps_per_epoch=len(x_train)/batch_size, # Run same number of steps we would if we were not using a generator.\n",
    "          validation_data=(x_valid, y_valid))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
