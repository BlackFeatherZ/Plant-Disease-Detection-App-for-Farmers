{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plant Disease Using Siamese Network - Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend as K\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Input, Lambda, Dense, Dropout, Convolution2D, MaxPooling2D, Flatten\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import optimizers\n",
    "\n",
    "import matplotlib.image as mpimg \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "import os\n",
    "from keras.models import Model,load_model\n",
    "import json\n",
    "from keras.models import model_from_json, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_image_size = 224\n",
    "resize = True\n",
    "total_sample_size = 10000 # 5k-50k\n",
    "\n",
    "channel = 1\n",
    "size = 2\n",
    "\n",
    "folder_count = 38\n",
    "image_count = 20 #0-50\n",
    "\n",
    "if resize == True:\n",
    "    batch_size=256\n",
    "else:\n",
    "    batch_size=64\n",
    "\n",
    "path =  os.path.join('../input/plantvillage/plantvillage_resize_224/PlantVillage_resize_224/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(filename, byteorder='>'):\n",
    "    \n",
    "    #first we read the image, as a raw file to the buffer\n",
    "    with open(filename, 'rb') as f:\n",
    "        buffer = f.read()\n",
    "    \n",
    "    #using regex, we extract the header, width, height and maxval of the image\n",
    "    header, width, height, maxval = re.search(\n",
    "        b\"(^P5\\s(?:\\s*#.*[\\r\\n])*\"\n",
    "        b\"(\\d+)\\s(?:\\s*#.*[\\r\\n])*\"\n",
    "        b\"(\\d+)\\s(?:\\s*#.*[\\r\\n])*\"\n",
    "        b\"(\\d+)\\s(?:\\s*#.*[\\r\\n]\\s)*)\", buffer).groups()\n",
    "    \n",
    "    #then we convert the image to numpy array using np.frombuffer which interprets buffer as one dimensional array\n",
    "    return np.frombuffer(buffer,\n",
    "                            dtype='u1' if int(maxval) < 256 else byteorder+'u2',\n",
    "                            count=int(width)*int(height),\n",
    "                            offset=len(header)\n",
    "                            ).reshape((int(height), int(width)))\n",
    "\n",
    "\n",
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))\n",
    "\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    margin = 1\n",
    "    return K.mean(y_true * K.square(y_pred) + (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))\n",
    "\n",
    "def compute_accuracy(predictions, labels):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    return labels[predictions.ravel() < 0.5].mean()\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(size, total_sample_size):\n",
    "    #read the image\n",
    "    image = mpimg.imread(path+'s' + str(1) + '/' + str(1) + '.jpg', 'rw+')\n",
    "    #reduce the size\n",
    "    if resize == True:\n",
    "        image = image[::size, ::size]\n",
    "    #get the new size\n",
    "    dim1 = image.shape[0]\n",
    "    dim2 = image.shape[1]\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    #initialize the numpy array with the shape of [total_sample, no_of_pairs, dim1, dim2]\n",
    "    x_geuine_pair = np.zeros([total_sample_size, 2, 1, dim1, dim2])\n",
    "\n",
    "    y_genuine = np.zeros([total_sample_size,1])\n",
    "\n",
    "    for i in range(folder_count):\n",
    "        for j in range(int(total_sample_size/folder_count)):\n",
    "            ind1 = 0\n",
    "            ind2 = 0\n",
    "\n",
    "            #read images from same directory (genuine pair)\n",
    "            while ind1 == ind2:\n",
    "                ind1 = np.random.randint(image_count)\n",
    "                ind2 = np.random.randint(image_count)\n",
    "\n",
    "            # read the two images\n",
    "            img1 = mpimg.imread(path+'s' + str(i+1) + '/' + str(ind1 + 1) + '.jpg', 'rw+')\n",
    "            img2 = mpimg.imread(path+'s' + str(i+1) + '/' + str(ind2 + 1) + '.jpg', 'rw+')\n",
    "\n",
    "            #reduce the size\n",
    "            if resize == True:\n",
    "                img1 = img1[::size, ::size]\n",
    "                img2 = img2[::size, ::size]\n",
    "\n",
    "            #store the images to the initialized numpy array\n",
    "            print\n",
    "            x_geuine_pair[count, 0, 0, :, :] = img1\n",
    "            x_geuine_pair[count, 1, 0, :, :] = img2\n",
    "\n",
    "            #as we are drawing images from the same directory we assign label as 1. (genuine pair)\n",
    "            y_genuine[count] = 1\n",
    "            count += 1\n",
    "\n",
    "    count = 0\n",
    "    x_imposite_pair = np.zeros([total_sample_size, 2, 1, dim1, dim2])\n",
    "    y_imposite = np.zeros([total_sample_size, 1])\n",
    "\n",
    "    for i in range(int(total_sample_size/image_count)):\n",
    "        for j in range(image_count):\n",
    "\n",
    "            #read images from different directory (imposite pair)\n",
    "            while True:\n",
    "                ind1 = np.random.randint(folder_count)\n",
    "                ind2 = np.random.randint(folder_count)\n",
    "                if ind1 != ind2:\n",
    "                    break\n",
    "\n",
    "            img1 = mpimg.imread(path+'s' + str(ind1+1) + '/' + str(j + 1) + '.jpg', 'rw+')\n",
    "            img2 = mpimg.imread(path+'s' + str(ind2+1) + '/' + str(j + 1) + '.jpg', 'rw+')\n",
    "\n",
    "            if resize == True:\n",
    "                img1 = img1[::size, ::size]\n",
    "                img2 = img2[::size, ::size]\n",
    "\n",
    "            x_imposite_pair[count, 0, 0, :, :] = img1\n",
    "            x_imposite_pair[count, 1, 0, :, :] = img2\n",
    "            #as we are drawing images from the different directory we assign label as 0. (imposite pair)\n",
    "            y_imposite[count] = 0\n",
    "            count += 1\n",
    "\n",
    "    #now, concatenate, genuine pairs and imposite pair to get the whole data\n",
    "    #print(x_geuine_pair.shape)\n",
    "    #print(x_imposite_pair.shape)\n",
    "    X = np.concatenate([x_geuine_pair, x_imposite_pair], axis=0)/255\n",
    "    Y = np.concatenate([y_genuine, y_imposite], axis=0)\n",
    "\n",
    "    return X, Y\n",
    "X, Y = get_data(size, total_sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we split our data for training and testing with 85% training and 15% testing proportions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_base_network(input_shape):\n",
    "    \n",
    "    seq = Sequential()\n",
    "    \n",
    "    nb_filter = [16, 32, 16]\n",
    "    kernel_size = 3\n",
    "    \n",
    "    \n",
    "    #convolutional layer 1\n",
    "    seq.add(Convolution2D(nb_filter[0], kernel_size, kernel_size, input_shape=input_shape,border_mode='valid', dim_ordering='th'))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))  \n",
    "    seq.add(Dropout(.25))\n",
    "    \n",
    "    #convolutional layer 2\n",
    "    seq.add(Convolution2D(nb_filter[1], kernel_size, kernel_size, border_mode='valid', dim_ordering='th'))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2), dim_ordering='th')) \n",
    "    seq.add(Dropout(.25))\n",
    "    \n",
    "    #convolutional layer 2\n",
    "    seq.add(Convolution2D(nb_filter[2], kernel_size, kernel_size, border_mode='valid', dim_ordering='th'))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2), dim_ordering='th')) \n",
    "    seq.add(Dropout(.25))\n",
    "\n",
    "    #flatten \n",
    "    seq.add(Flatten())\n",
    "    seq.add(Dense(128, activation='relu'))\n",
    "    seq.add(Dropout(0.1))\n",
    "    seq.add(Dense(38, activation='relu'))\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = x_train.shape[2:]\n",
    "img_a = Input(shape=input_dim)\n",
    "img_b = Input(shape=input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_network = build_base_network(input_dim)\n",
    "feat_vecs_a = base_network(img_a)\n",
    "feat_vecs_b = base_network(img_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([feat_vecs_a, feat_vecs_b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "rms = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)#RMSprop()\n",
    "rms = RMSprop()\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0,\n",
    "                              patience=3,\n",
    "                              verbose=1,\n",
    "                              restore_best_weights=True)\n",
    "callback_early_stop_reduceLROnPlateau=[earlyStopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T14:59:56.375999Z",
     "iopub.status.busy": "2022-12-20T14:59:56.375657Z",
     "iopub.status.idle": "2022-12-20T14:59:56.383498Z",
     "shell.execute_reply": "2022-12-20T14:59:56.382589Z",
     "shell.execute_reply.started": "2022-12-20T14:59:56.375940Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1, 112, 112)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1, 112, 112)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 38)           652674      input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1)            0           sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "==================================================================================================\n",
      "Total params: 652,674\n",
      "Trainable params: 652,674\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(input=[img_a, img_b], output=distance)\n",
    "model.compile(loss=contrastive_loss, optimizer=rms,metrics=[accuracy])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T15:00:26.473202Z",
     "iopub.status.busy": "2022-12-20T15:00:26.472898Z",
     "iopub.status.idle": "2022-12-20T15:00:26.480012Z",
     "shell.execute_reply": "2022-12-20T15:00:26.479081Z",
     "shell.execute_reply.started": "2022-12-20T15:00:26.473153Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13600 samples, validate on 3400 samples\n",
      "Epoch 1/20\n",
      "13600/13600 [==============================] - 10s 764us/step - loss: 0.2560 - accuracy: 0.5660 - val_loss: 0.2959 - val_accuracy: 0.5329\n",
      "Epoch 2/20\n",
      "13600/13600 [==============================] - 6s 459us/step - loss: 0.2105 - accuracy: 0.6762 - val_loss: 0.2961 - val_accuracy: 0.5235\n",
      "Epoch 3/20\n",
      "13600/13600 [==============================] - 6s 453us/step - loss: 0.1790 - accuracy: 0.7382 - val_loss: 0.1709 - val_accuracy: 0.7441\n",
      "Epoch 4/20\n",
      "13600/13600 [==============================] - 6s 467us/step - loss: 0.1570 - accuracy: 0.7854 - val_loss: 0.1511 - val_accuracy: 0.7894\n",
      "Epoch 5/20\n",
      "13600/13600 [==============================] - 6s 462us/step - loss: 0.1319 - accuracy: 0.8375 - val_loss: 0.1197 - val_accuracy: 0.8479\n",
      "Epoch 6/20\n",
      "13600/13600 [==============================] - 6s 465us/step - loss: 0.1139 - accuracy: 0.8715 - val_loss: 0.1212 - val_accuracy: 0.8403\n",
      "Epoch 7/20\n",
      "13600/13600 [==============================] - 6s 468us/step - loss: 0.0971 - accuracy: 0.9030 - val_loss: 0.0970 - val_accuracy: 0.8888\n",
      "Epoch 8/20\n",
      "13600/13600 [==============================] - 6s 474us/step - loss: 0.0862 - accuracy: 0.9234 - val_loss: 0.0725 - val_accuracy: 0.9209\n",
      "Epoch 9/20\n",
      "13600/13600 [==============================] - 6s 469us/step - loss: 0.0761 - accuracy: 0.9414 - val_loss: 0.0663 - val_accuracy: 0.9282\n",
      "Epoch 10/20\n",
      "13600/13600 [==============================] - 6s 466us/step - loss: 0.0680 - accuracy: 0.9510 - val_loss: 0.0603 - val_accuracy: 0.9412\n",
      "Epoch 11/20\n",
      "13600/13600 [==============================] - 6s 463us/step - loss: 0.0309 - accuracy: 0.9621- val_loss: 0.0450 - val_accuracy: 0.9362\n",
      "Epoch 12/20\n",
      "13600/13600 [==============================] - 6s 458us/step - loss: 0.0311 - accuracy: 0.9641 - val_loss: 0.0421 - val_accuracy: 0.9432\n"
     ]
    }
   ],
   "source": [
    "img_1 = x_train[:, 0]\n",
    "img2 = x_train[:, 1]\n",
    "img_1.shape\n",
    "history = model.fit([img_1, img2], y_train, validation_split=.20,\n",
    "      batch_size= batch_size, verbose=1, nb_epoch=epochs, callbacks=callback_early_stop_reduceLROnPlateau)\n",
    "\n",
    "# Option 1: Save Weights + Architecture\n",
    "model.save_weights('model_weights.h5')\n",
    "with open('model_architecture.json', 'w') as f:\n",
    "    f.write(model.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
